{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f58cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"PreAnxiety.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a7e56f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. Age</th>\n",
       "      <th>2. Gender</th>\n",
       "      <th>3. University</th>\n",
       "      <th>4. Department</th>\n",
       "      <th>5. Academic Year</th>\n",
       "      <th>6. Current CGPA</th>\n",
       "      <th>7. Did you receive a waiver or scholarship at your university?</th>\n",
       "      <th>Anxiety Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Independent University, Bangladesh (IUB)</td>\n",
       "      <td>Engineering - CS / CSE / CSC / Similar to CS</td>\n",
       "      <td>Second Year or Equivalent</td>\n",
       "      <td>2.50 - 2.99</td>\n",
       "      <td>No</td>\n",
       "      <td>More Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Independent University, Bangladesh (IUB)</td>\n",
       "      <td>Engineering - CS / CSE / CSC / Similar to CS</td>\n",
       "      <td>Third Year or Equivalent</td>\n",
       "      <td>3.00 - 3.39</td>\n",
       "      <td>No</td>\n",
       "      <td>More Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-22</td>\n",
       "      <td>Male</td>\n",
       "      <td>American International University Bangladesh (...</td>\n",
       "      <td>Engineering - CS / CSE / CSC / Similar to CS</td>\n",
       "      <td>Third Year or Equivalent</td>\n",
       "      <td>3.00 - 3.39</td>\n",
       "      <td>No</td>\n",
       "      <td>Less Anxious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  1. Age 2. Gender                                      3. University  \\\n",
       "0  18-22    Female           Independent University, Bangladesh (IUB)   \n",
       "1  18-22      Male           Independent University, Bangladesh (IUB)   \n",
       "2  18-22      Male  American International University Bangladesh (...   \n",
       "\n",
       "                                  4. Department           5. Academic Year  \\\n",
       "0  Engineering - CS / CSE / CSC / Similar to CS  Second Year or Equivalent   \n",
       "1  Engineering - CS / CSE / CSC / Similar to CS   Third Year or Equivalent   \n",
       "2  Engineering - CS / CSE / CSC / Similar to CS   Third Year or Equivalent   \n",
       "\n",
       "  6. Current CGPA  \\\n",
       "0     2.50 - 2.99   \n",
       "1     3.00 - 3.39   \n",
       "2     3.00 - 3.39   \n",
       "\n",
       "  7. Did you receive a waiver or scholarship at your university? Anxiety Label  \n",
       "0                                                 No              More Anxious  \n",
       "1                                                 No              More Anxious  \n",
       "2                                                 No              Less Anxious  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650e5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,0:7]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9af4258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "More Anxious    1869\n",
       "Less Anxious     159\n",
       "Name: Anxiety Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0eaab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['More Anxious', 'Less Anxious'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d5d03",
   "metadata": {},
   "source": [
    "<!-- Our Dataset seems to be imbalance, Lets fix this imbalance using SMOTE -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf0af9",
   "metadata": {},
   "source": [
    "## Dataset is highly imbalanced, let's balance it using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0c6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dum = pd.get_dummies(x,drop_first=True, dtype=int)\n",
    "y_dum = pd.get_dummies(y,drop_first=True,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb310ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9216da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f80908c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_resampled, y_resampled = sm.fit_resample(x_dum,y_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638d8ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_resampled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fae69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "More Anxious\n",
       "0               1869\n",
       "1               1869\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db8546",
   "metadata": {},
   "source": [
    "# Now we got the balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c983896",
   "metadata": {},
   "source": [
    "# Feature Selection Using Select K Best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8f35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e13931",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectBest = SelectKBest(score_func=chi2, k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ee3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectkbest = selectBest.fit(x_resampled,y_resampled).transform(x_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70b77728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectkbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7cb423c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [200, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [200, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [200, 100]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\":[200,100],\n",
    "    'max_features':['sqrt', 'log2', None],\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,scoring=\"accuracy\",verbose=3,refit=True,n_jobs=-1)\n",
    "grid.fit(selectkbest,y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b634452",
   "metadata": {},
   "source": [
    "## Result of Select K for 15 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bcdb5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.908838</td>\n",
       "      <td>0.082956</td>\n",
       "      <td>0.043797</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.705998</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.018250</td>\n",
       "      <td>0.030525</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706533</td>\n",
       "      <td>0.022076</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752458</td>\n",
       "      <td>0.019155</td>\n",
       "      <td>0.048960</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.721925</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.705489</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.707068</td>\n",
       "      <td>0.023971</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353058</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.705998</td>\n",
       "      <td>0.023569</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.209437</td>\n",
       "      <td>0.285204</td>\n",
       "      <td>0.062897</td>\n",
       "      <td>0.028419</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.022038</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.024741</td>\n",
       "      <td>0.299991</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>0.701473</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.705730</td>\n",
       "      <td>0.023203</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.019339</td>\n",
       "      <td>0.049792</td>\n",
       "      <td>0.127877</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.664439</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706266</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.052080</td>\n",
       "      <td>0.047826</td>\n",
       "      <td>0.074290</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.664439</td>\n",
       "      <td>0.723262</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>0.705489</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.707336</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.036343</td>\n",
       "      <td>0.051481</td>\n",
       "      <td>0.129099</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.712567</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.705196</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.064856</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.070802</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.705998</td>\n",
       "      <td>0.023569</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.847566</td>\n",
       "      <td>0.113891</td>\n",
       "      <td>0.133718</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.721925</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.701473</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.344041</td>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.065795</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.721925</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.701473</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.049024</td>\n",
       "      <td>0.028260</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.712567</td>\n",
       "      <td>0.705489</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.705731</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706533</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.025623</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>0.120249</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.664439</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706266</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.014701</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.070405</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.721925</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.705489</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706801</td>\n",
       "      <td>0.023871</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.738055</td>\n",
       "      <td>0.032785</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706533</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.270108</td>\n",
       "      <td>0.058882</td>\n",
       "      <td>0.051169</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.721925</td>\n",
       "      <td>0.712567</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.729585</td>\n",
       "      <td>0.706266</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.908838      0.082956         0.043797        0.004714   \n",
       "1        0.386957      0.018250         0.030525        0.008530   \n",
       "2        0.752458      0.019155         0.048960        0.004973   \n",
       "3        0.353058      0.008481         0.034999        0.007128   \n",
       "4        1.209437      0.285204         0.062897        0.028419   \n",
       "5        1.024741      0.299991         0.071194        0.010667   \n",
       "6        2.019339      0.049792         0.127877        0.010188   \n",
       "7        1.052080      0.047826         0.074290        0.006450   \n",
       "8        2.036343      0.051481         0.129099        0.020424   \n",
       "9        1.064856      0.023545         0.070802        0.008540   \n",
       "10       2.847566      0.113891         0.133718        0.021082   \n",
       "11       1.344041      0.056764         0.065795        0.003136   \n",
       "12       2.049024      0.028260         0.123044        0.004119   \n",
       "13       0.999592      0.028439         0.070751        0.012359   \n",
       "14       2.025623      0.050673         0.120249        0.011021   \n",
       "15       1.014701      0.060149         0.070405        0.015835   \n",
       "16       2.738055      0.032785         0.123028        0.007912   \n",
       "17       1.270108      0.058882         0.051169        0.020377   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0             gini               sqrt                200   \n",
       "1             gini               sqrt                100   \n",
       "2             gini               log2                200   \n",
       "3             gini               log2                100   \n",
       "4             gini               None                200   \n",
       "5             gini               None                100   \n",
       "6          entropy               sqrt                200   \n",
       "7          entropy               sqrt                100   \n",
       "8          entropy               log2                200   \n",
       "9          entropy               log2                100   \n",
       "10         entropy               None                200   \n",
       "11         entropy               None                100   \n",
       "12        log_loss               sqrt                200   \n",
       "13        log_loss               sqrt                100   \n",
       "14        log_loss               log2                200   \n",
       "15        log_loss               log2                100   \n",
       "16        log_loss               None                200   \n",
       "17        log_loss               None                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.663102   \n",
       "1   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.665775   \n",
       "2   {'criterion': 'gini', 'max_features': 'log2', ...           0.661765   \n",
       "3   {'criterion': 'gini', 'max_features': 'log2', ...           0.661765   \n",
       "4   {'criterion': 'gini', 'max_features': None, 'n...           0.665775   \n",
       "5   {'criterion': 'gini', 'max_features': None, 'n...           0.663102   \n",
       "6   {'criterion': 'entropy', 'max_features': 'sqrt...           0.664439   \n",
       "7   {'criterion': 'entropy', 'max_features': 'sqrt...           0.664439   \n",
       "8   {'criterion': 'entropy', 'max_features': 'log2...           0.661765   \n",
       "9   {'criterion': 'entropy', 'max_features': 'log2...           0.661765   \n",
       "10  {'criterion': 'entropy', 'max_features': None,...           0.665775   \n",
       "11  {'criterion': 'entropy', 'max_features': None,...           0.665775   \n",
       "12  {'criterion': 'log_loss', 'max_features': 'sqr...           0.661765   \n",
       "13  {'criterion': 'log_loss', 'max_features': 'sqr...           0.665775   \n",
       "14  {'criterion': 'log_loss', 'max_features': 'log...           0.664439   \n",
       "15  {'criterion': 'log_loss', 'max_features': 'log...           0.661765   \n",
       "16  {'criterion': 'log_loss', 'max_features': None...           0.665775   \n",
       "17  {'criterion': 'log_loss', 'max_features': None...           0.663102   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.719251           0.713904           0.704150   \n",
       "1            0.717914           0.716578           0.702811   \n",
       "2            0.721925           0.716578           0.705489   \n",
       "3            0.719251           0.715241           0.704150   \n",
       "4            0.717914           0.716578           0.704150   \n",
       "5            0.720588           0.713904           0.701473   \n",
       "6            0.719251           0.713904           0.704150   \n",
       "7            0.723262           0.713904           0.705489   \n",
       "8            0.719251           0.712567           0.702811   \n",
       "9            0.719251           0.715241           0.704150   \n",
       "10           0.721925           0.715241           0.701473   \n",
       "11           0.721925           0.715241           0.701473   \n",
       "12           0.719251           0.712567           0.705489   \n",
       "13           0.716578           0.716578           0.704150   \n",
       "14           0.717914           0.715241           0.704150   \n",
       "15           0.721925           0.715241           0.705489   \n",
       "16           0.717914           0.715241           0.704150   \n",
       "17           0.721925           0.712567           0.704150   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.729585         0.705998        0.022970               13  \n",
       "1            0.729585         0.706533        0.022076                9  \n",
       "2            0.729585         0.707068        0.023971                2  \n",
       "3            0.729585         0.705998        0.023569               13  \n",
       "4            0.729585         0.706800        0.022038                4  \n",
       "5            0.729585         0.705730        0.023203               17  \n",
       "6            0.729585         0.706266        0.022471               10  \n",
       "7            0.729585         0.707336        0.022958                1  \n",
       "8            0.729585         0.705196        0.023404               18  \n",
       "9            0.729585         0.705998        0.023569               13  \n",
       "10           0.729585         0.706800        0.022497                5  \n",
       "11           0.729585         0.706800        0.022497                5  \n",
       "12           0.729585         0.705731        0.023374               16  \n",
       "13           0.729585         0.706533        0.021909                7  \n",
       "14           0.729585         0.706266        0.022423               10  \n",
       "15           0.729585         0.706801        0.023871                3  \n",
       "16           0.729585         0.706533        0.021925                7  \n",
       "17           0.729585         0.706266        0.023222               10  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493d384",
   "metadata": {},
   "source": [
    "## Select K Feature Selection has given us Accuracy of 70.76% with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acaf874",
   "metadata": {},
   "source": [
    "# Feature Selection Using RFE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dafa40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X[:, features], y, **fit_params)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:326: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X[:, features], y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(solver='lbfgs')\n",
    "RF = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "DT= DecisionTreeClassifier(criterion = 'gini', max_features='sqrt',splitter='best',random_state = 0)\n",
    "svc_model = SVC(kernel = 'linear', random_state = 0)\n",
    "rfemodellist=[log_model,svc_model,RF,DT] \n",
    "log_rfe_feature=[]\n",
    "Selected_features = []\n",
    "for i in   rfemodellist:\n",
    "    print(i)\n",
    "    log_rfe = RFE(estimator=i,n_features_to_select=15)\n",
    "    log_fit = log_rfe.fit(x_resampled, y_resampled)\n",
    "    log_rfe_feature.append(log_fit.transform(x_resampled))\n",
    "    Selected_features.append(x_resampled.columns[log_fit.support_])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e41e0",
   "metadata": {},
   "source": [
    "## Using Random Forest Selected features from RFE to Train Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e06feac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\":[200,100],\n",
    "    'max_features':['sqrt', 'log2', None],\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,scoring=\"accuracy\",verbose=3,refit=True,n_jobs=-1)\n",
    "best_model = grid.fit(log_rfe_feature[2],y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35184822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.438919</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.140031</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.792781</td>\n",
       "      <td>0.824866</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>0.025082</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.200707</td>\n",
       "      <td>0.044946</td>\n",
       "      <td>0.082712</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.791444</td>\n",
       "      <td>0.827540</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.795885</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.405783</td>\n",
       "      <td>0.046051</td>\n",
       "      <td>0.148409</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.798128</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.798830</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.194213</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.085907</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.752674</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.797223</td>\n",
       "      <td>0.024238</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.356051</td>\n",
       "      <td>0.057795</td>\n",
       "      <td>0.144828</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.744652</td>\n",
       "      <td>0.792781</td>\n",
       "      <td>0.827540</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.813922</td>\n",
       "      <td>0.794815</td>\n",
       "      <td>0.028130</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.671752</td>\n",
       "      <td>0.080245</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.011659</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.743316</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.820856</td>\n",
       "      <td>0.800535</td>\n",
       "      <td>0.816600</td>\n",
       "      <td>0.795085</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.443315</td>\n",
       "      <td>0.079394</td>\n",
       "      <td>0.126175</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.748663</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.819519</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>0.024916</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.238850</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.076005</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.788770</td>\n",
       "      <td>0.824866</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>0.816600</td>\n",
       "      <td>0.796422</td>\n",
       "      <td>0.026304</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.429241</td>\n",
       "      <td>0.065646</td>\n",
       "      <td>0.136865</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.752674</td>\n",
       "      <td>0.799465</td>\n",
       "      <td>0.820856</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>0.813922</td>\n",
       "      <td>0.797758</td>\n",
       "      <td>0.023863</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.190082</td>\n",
       "      <td>0.044166</td>\n",
       "      <td>0.074964</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.824866</td>\n",
       "      <td>0.800535</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>0.024999</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.415097</td>\n",
       "      <td>0.063674</td>\n",
       "      <td>0.140205</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.744652</td>\n",
       "      <td>0.791444</td>\n",
       "      <td>0.822193</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.695442</td>\n",
       "      <td>0.033232</td>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.015582</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.743316</td>\n",
       "      <td>0.798128</td>\n",
       "      <td>0.826203</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.795618</td>\n",
       "      <td>0.028179</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.415627</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.142416</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.826203</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.813922</td>\n",
       "      <td>0.797222</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.217084</td>\n",
       "      <td>0.068650</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.790107</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>0.813922</td>\n",
       "      <td>0.794817</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.407388</td>\n",
       "      <td>0.103695</td>\n",
       "      <td>0.133568</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.788770</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.794548</td>\n",
       "      <td>0.024618</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.222357</td>\n",
       "      <td>0.041133</td>\n",
       "      <td>0.074643</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.752674</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.826203</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.816600</td>\n",
       "      <td>0.798025</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.361096</td>\n",
       "      <td>0.066551</td>\n",
       "      <td>0.119940</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.745989</td>\n",
       "      <td>0.790107</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.647649</td>\n",
       "      <td>0.124050</td>\n",
       "      <td>0.073772</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.744652</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.819519</td>\n",
       "      <td>0.796519</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.793210</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.438919      0.017907         0.140031        0.022664   \n",
       "1        1.200707      0.044946         0.082712        0.011119   \n",
       "2        2.405783      0.046051         0.148409        0.013307   \n",
       "3        1.194213      0.020588         0.085907        0.009407   \n",
       "4        3.356051      0.057795         0.144828        0.008422   \n",
       "5        1.671752      0.080245         0.070382        0.011659   \n",
       "6        2.443315      0.079394         0.126175        0.013930   \n",
       "7        1.238850      0.044994         0.076005        0.008393   \n",
       "8        2.429241      0.065646         0.136865        0.018817   \n",
       "9        1.190082      0.044166         0.074964        0.015141   \n",
       "10       3.415097      0.063674         0.140205        0.011669   \n",
       "11       1.695442      0.033232         0.079909        0.015582   \n",
       "12       2.415627      0.020258         0.142416        0.014096   \n",
       "13       1.217084      0.068650         0.083203        0.010602   \n",
       "14       2.407388      0.103695         0.133568        0.002012   \n",
       "15       1.222357      0.041133         0.074643        0.005455   \n",
       "16       3.361096      0.066551         0.119940        0.011218   \n",
       "17       1.647649      0.124050         0.073772        0.021928   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0             gini               sqrt                200   \n",
       "1             gini               sqrt                100   \n",
       "2             gini               log2                200   \n",
       "3             gini               log2                100   \n",
       "4             gini               None                200   \n",
       "5             gini               None                100   \n",
       "6          entropy               sqrt                200   \n",
       "7          entropy               sqrt                100   \n",
       "8          entropy               log2                200   \n",
       "9          entropy               log2                100   \n",
       "10         entropy               None                200   \n",
       "11         entropy               None                100   \n",
       "12        log_loss               sqrt                200   \n",
       "13        log_loss               sqrt                100   \n",
       "14        log_loss               log2                200   \n",
       "15        log_loss               log2                100   \n",
       "16        log_loss               None                200   \n",
       "17        log_loss               None                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.751337   \n",
       "1   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.750000   \n",
       "2   {'criterion': 'gini', 'max_features': 'log2', ...           0.750000   \n",
       "3   {'criterion': 'gini', 'max_features': 'log2', ...           0.752674   \n",
       "4   {'criterion': 'gini', 'max_features': None, 'n...           0.744652   \n",
       "5   {'criterion': 'gini', 'max_features': None, 'n...           0.743316   \n",
       "6   {'criterion': 'entropy', 'max_features': 'sqrt...           0.748663   \n",
       "7   {'criterion': 'entropy', 'max_features': 'sqrt...           0.750000   \n",
       "8   {'criterion': 'entropy', 'max_features': 'log2...           0.752674   \n",
       "9   {'criterion': 'entropy', 'max_features': 'log2...           0.751337   \n",
       "10  {'criterion': 'entropy', 'max_features': None,...           0.744652   \n",
       "11  {'criterion': 'entropy', 'max_features': None,...           0.743316   \n",
       "12  {'criterion': 'log_loss', 'max_features': 'sqr...           0.751337   \n",
       "13  {'criterion': 'log_loss', 'max_features': 'sqr...           0.750000   \n",
       "14  {'criterion': 'log_loss', 'max_features': 'log...           0.751337   \n",
       "15  {'criterion': 'log_loss', 'max_features': 'log...           0.752674   \n",
       "16  {'criterion': 'log_loss', 'max_features': None...           0.745989   \n",
       "17  {'criterion': 'log_loss', 'max_features': None...           0.744652   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.792781           0.824866           0.801874   \n",
       "1            0.791444           0.827540           0.797858   \n",
       "2            0.798128           0.823529           0.803213   \n",
       "3            0.795455           0.823529           0.801874   \n",
       "4            0.792781           0.827540           0.795181   \n",
       "5            0.794118           0.820856           0.800535   \n",
       "6            0.796791           0.819519           0.801874   \n",
       "7            0.788770           0.824866           0.801874   \n",
       "8            0.799465           0.820856           0.801874   \n",
       "9            0.794118           0.824866           0.800535   \n",
       "10           0.791444           0.822193           0.797858   \n",
       "11           0.798128           0.826203           0.797858   \n",
       "12           0.796791           0.826203           0.797858   \n",
       "13           0.790107           0.818182           0.801874   \n",
       "14           0.788770           0.823529           0.797858   \n",
       "15           0.796791           0.826203           0.797858   \n",
       "16           0.790107           0.823529           0.797858   \n",
       "17           0.795455           0.819519           0.796519   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.812584         0.796688        0.025082                6  \n",
       "1            0.812584         0.795885        0.026115               10  \n",
       "2            0.819277         0.798830        0.026200                1  \n",
       "3            0.812584         0.797223        0.024238                4  \n",
       "4            0.813922         0.794815        0.028130               14  \n",
       "5            0.816600         0.795085        0.027705               12  \n",
       "6            0.812584         0.795886        0.024916                9  \n",
       "7            0.816600         0.796422        0.026304                8  \n",
       "8            0.813922         0.797758        0.023863                3  \n",
       "9            0.812584         0.796688        0.024999                7  \n",
       "10           0.811245         0.793478        0.026636               17  \n",
       "11           0.812584         0.795618        0.028179               11  \n",
       "12           0.813922         0.797222        0.025396                5  \n",
       "13           0.813922         0.794817        0.024460               13  \n",
       "14           0.811245         0.794548        0.024618               16  \n",
       "15           0.816600         0.798025        0.025288                2  \n",
       "16           0.815261         0.794549        0.027047               15  \n",
       "17           0.809906         0.793210        0.025864               18  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a328d2d",
   "metadata": {},
   "source": [
    "# For 15 Features, Random Forest has given us better accuracy of 79.72%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e458872",
   "metadata": {},
   "source": [
    "## Using SVC Selected features from RFE to Train Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "294875f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [200, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [200, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [200, 100]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\":[200,100],\n",
    "    'max_features':['sqrt', 'log2', None],\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,scoring=\"accuracy\",verbose=3,refit=True,n_jobs=-1)\n",
    "grid.fit(log_rfe_feature[1],y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3c5a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705341</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.349619</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710183</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.045459</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360092</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.028017</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.899858</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.059029</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.627249</td>\n",
       "      <td>0.255095</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.148342</td>\n",
       "      <td>0.104130</td>\n",
       "      <td>0.114763</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.055094</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.075825</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.114423</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.142475</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.032298</td>\n",
       "      <td>0.066729</td>\n",
       "      <td>0.074924</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.561797</td>\n",
       "      <td>0.085042</td>\n",
       "      <td>0.116348</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.194399</td>\n",
       "      <td>0.056536</td>\n",
       "      <td>0.067039</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.939817</td>\n",
       "      <td>0.054309</td>\n",
       "      <td>0.120809</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.003516</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.903197</td>\n",
       "      <td>0.092825</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.920243</td>\n",
       "      <td>0.035775</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.376946</td>\n",
       "      <td>0.061895</td>\n",
       "      <td>0.110501</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.158449</td>\n",
       "      <td>0.069517</td>\n",
       "      <td>0.050450</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.716198</td>\n",
       "      <td>0.713521</td>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.705341      0.014709         0.043906        0.005603   \n",
       "1        0.349619      0.012465         0.017747        0.003040   \n",
       "2        0.710183      0.031915         0.045459        0.003840   \n",
       "3        0.360092      0.013033         0.028017        0.004567   \n",
       "4        0.899858      0.076273         0.059029        0.035088   \n",
       "5        0.627249      0.255095         0.046232        0.015989   \n",
       "6        2.148342      0.104130         0.114763        0.014631   \n",
       "7        1.055094      0.045027         0.075825        0.012732   \n",
       "8        2.114423      0.067031         0.142475        0.027470   \n",
       "9        1.032298      0.066729         0.074924        0.008282   \n",
       "10       2.561797      0.085042         0.116348        0.010304   \n",
       "11       1.194399      0.056536         0.067039        0.009719   \n",
       "12       1.939817      0.054309         0.120809        0.012763   \n",
       "13       1.003516      0.058593         0.070486        0.014776   \n",
       "14       1.903197      0.092825         0.123702        0.005505   \n",
       "15       0.920243      0.035775         0.067978        0.006382   \n",
       "16       2.376946      0.061895         0.110501        0.013530   \n",
       "17       1.158449      0.069517         0.050450        0.014777   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0             gini               sqrt                200   \n",
       "1             gini               sqrt                100   \n",
       "2             gini               log2                200   \n",
       "3             gini               log2                100   \n",
       "4             gini               None                200   \n",
       "5             gini               None                100   \n",
       "6          entropy               sqrt                200   \n",
       "7          entropy               sqrt                100   \n",
       "8          entropy               log2                200   \n",
       "9          entropy               log2                100   \n",
       "10         entropy               None                200   \n",
       "11         entropy               None                100   \n",
       "12        log_loss               sqrt                200   \n",
       "13        log_loss               sqrt                100   \n",
       "14        log_loss               log2                200   \n",
       "15        log_loss               log2                100   \n",
       "16        log_loss               None                200   \n",
       "17        log_loss               None                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.663102   \n",
       "1   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.663102   \n",
       "2   {'criterion': 'gini', 'max_features': 'log2', ...           0.663102   \n",
       "3   {'criterion': 'gini', 'max_features': 'log2', ...           0.663102   \n",
       "4   {'criterion': 'gini', 'max_features': None, 'n...           0.663102   \n",
       "5   {'criterion': 'gini', 'max_features': None, 'n...           0.663102   \n",
       "6   {'criterion': 'entropy', 'max_features': 'sqrt...           0.663102   \n",
       "7   {'criterion': 'entropy', 'max_features': 'sqrt...           0.663102   \n",
       "8   {'criterion': 'entropy', 'max_features': 'log2...           0.663102   \n",
       "9   {'criterion': 'entropy', 'max_features': 'log2...           0.663102   \n",
       "10  {'criterion': 'entropy', 'max_features': None,...           0.663102   \n",
       "11  {'criterion': 'entropy', 'max_features': None,...           0.663102   \n",
       "12  {'criterion': 'log_loss', 'max_features': 'sqr...           0.663102   \n",
       "13  {'criterion': 'log_loss', 'max_features': 'sqr...           0.663102   \n",
       "14  {'criterion': 'log_loss', 'max_features': 'log...           0.663102   \n",
       "15  {'criterion': 'log_loss', 'max_features': 'log...           0.663102   \n",
       "16  {'criterion': 'log_loss', 'max_features': None...           0.663102   \n",
       "17  {'criterion': 'log_loss', 'max_features': None...           0.663102   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.708556           0.720588           0.716198   \n",
       "1            0.708556           0.720588           0.716198   \n",
       "2            0.708556           0.720588           0.716198   \n",
       "3            0.708556           0.720588           0.716198   \n",
       "4            0.708556           0.720588           0.716198   \n",
       "5            0.708556           0.720588           0.716198   \n",
       "6            0.708556           0.720588           0.716198   \n",
       "7            0.708556           0.720588           0.716198   \n",
       "8            0.708556           0.720588           0.716198   \n",
       "9            0.708556           0.720588           0.716198   \n",
       "10           0.708556           0.720588           0.716198   \n",
       "11           0.708556           0.720588           0.716198   \n",
       "12           0.708556           0.720588           0.716198   \n",
       "13           0.708556           0.720588           0.716198   \n",
       "14           0.708556           0.720588           0.716198   \n",
       "15           0.708556           0.720588           0.716198   \n",
       "16           0.708556           0.720588           0.716198   \n",
       "17           0.708556           0.720588           0.716198   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.713521         0.704393        0.021011                1  \n",
       "1            0.713521         0.704393        0.021011                1  \n",
       "2            0.713521         0.704393        0.021011                1  \n",
       "3            0.713521         0.704393        0.021011                1  \n",
       "4            0.713521         0.704393        0.021011                1  \n",
       "5            0.713521         0.704393        0.021011                1  \n",
       "6            0.713521         0.704393        0.021011                1  \n",
       "7            0.713521         0.704393        0.021011                1  \n",
       "8            0.713521         0.704393        0.021011                1  \n",
       "9            0.713521         0.704393        0.021011                1  \n",
       "10           0.713521         0.704393        0.021011                1  \n",
       "11           0.713521         0.704393        0.021011                1  \n",
       "12           0.713521         0.704393        0.021011                1  \n",
       "13           0.713521         0.704393        0.021011                1  \n",
       "14           0.713521         0.704393        0.021011                1  \n",
       "15           0.713521         0.704393        0.021011                1  \n",
       "16           0.713521         0.704393        0.021011                1  \n",
       "17           0.713521         0.704393        0.021011                1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc7701",
   "metadata": {},
   "source": [
    "## Using Logistic Regression Selected feature from RFE to Train Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9d23173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [200, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [200, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [200, 100]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\":[200,100],\n",
    "    'max_features':['sqrt', 'log2', None],\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,scoring=\"accuracy\",verbose=3,refit=True,n_jobs=-1)\n",
    "grid.fit(log_rfe_feature[0],y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a840442f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.983735</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>0.116385</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949452</td>\n",
       "      <td>0.048813</td>\n",
       "      <td>0.064410</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.939931</td>\n",
       "      <td>0.084626</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.012041</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990424</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.584702</td>\n",
       "      <td>0.128020</td>\n",
       "      <td>0.133426</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683526</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.301220</td>\n",
       "      <td>0.066267</td>\n",
       "      <td>0.092832</td>\n",
       "      <td>0.032224</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683526</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.928731</td>\n",
       "      <td>0.055288</td>\n",
       "      <td>0.126603</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.993543</td>\n",
       "      <td>0.050288</td>\n",
       "      <td>0.066763</td>\n",
       "      <td>0.012824</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.966498</td>\n",
       "      <td>0.049761</td>\n",
       "      <td>0.128990</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.976202</td>\n",
       "      <td>0.042720</td>\n",
       "      <td>0.069237</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.458685</td>\n",
       "      <td>0.039532</td>\n",
       "      <td>0.109643</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683526</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.249869</td>\n",
       "      <td>0.022125</td>\n",
       "      <td>0.073532</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.194567</td>\n",
       "      <td>0.060123</td>\n",
       "      <td>0.130532</td>\n",
       "      <td>0.014694</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.044020</td>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.080868</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.921527</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.942037</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>0.067361</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.434577</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0.115674</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683526</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.162135</td>\n",
       "      <td>0.052407</td>\n",
       "      <td>0.051030</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.643048</td>\n",
       "      <td>0.696524</td>\n",
       "      <td>0.68984</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.983735      0.039470         0.116385        0.018062   \n",
       "1        0.949452      0.048813         0.064410        0.012981   \n",
       "2        1.939931      0.084626         0.126858        0.012041   \n",
       "3        0.990424      0.061318         0.061799        0.007746   \n",
       "4        2.584702      0.128020         0.133426        0.016103   \n",
       "5        1.301220      0.066267         0.092832        0.032224   \n",
       "6        1.928731      0.055288         0.126603        0.006346   \n",
       "7        0.993543      0.050288         0.066763        0.012824   \n",
       "8        1.966498      0.049761         0.128990        0.015041   \n",
       "9        0.976202      0.042720         0.069237        0.002219   \n",
       "10       2.458685      0.039532         0.109643        0.008507   \n",
       "11       1.249869      0.022125         0.073532        0.012340   \n",
       "12       2.194567      0.060123         0.130532        0.014694   \n",
       "13       1.044020      0.079909         0.080868        0.014525   \n",
       "14       1.921527      0.059361         0.110845        0.013804   \n",
       "15       0.942037      0.031010         0.067361        0.010615   \n",
       "16       2.434577      0.053340         0.115674        0.010029   \n",
       "17       1.162135      0.052407         0.051030        0.012624   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0             gini               sqrt                200   \n",
       "1             gini               sqrt                100   \n",
       "2             gini               log2                200   \n",
       "3             gini               log2                100   \n",
       "4             gini               None                200   \n",
       "5             gini               None                100   \n",
       "6          entropy               sqrt                200   \n",
       "7          entropy               sqrt                100   \n",
       "8          entropy               log2                200   \n",
       "9          entropy               log2                100   \n",
       "10         entropy               None                200   \n",
       "11         entropy               None                100   \n",
       "12        log_loss               sqrt                200   \n",
       "13        log_loss               sqrt                100   \n",
       "14        log_loss               log2                200   \n",
       "15        log_loss               log2                100   \n",
       "16        log_loss               None                200   \n",
       "17        log_loss               None                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.643048   \n",
       "1   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.643048   \n",
       "2   {'criterion': 'gini', 'max_features': 'log2', ...           0.643048   \n",
       "3   {'criterion': 'gini', 'max_features': 'log2', ...           0.643048   \n",
       "4   {'criterion': 'gini', 'max_features': None, 'n...           0.643048   \n",
       "5   {'criterion': 'gini', 'max_features': None, 'n...           0.643048   \n",
       "6   {'criterion': 'entropy', 'max_features': 'sqrt...           0.643048   \n",
       "7   {'criterion': 'entropy', 'max_features': 'sqrt...           0.643048   \n",
       "8   {'criterion': 'entropy', 'max_features': 'log2...           0.643048   \n",
       "9   {'criterion': 'entropy', 'max_features': 'log2...           0.643048   \n",
       "10  {'criterion': 'entropy', 'max_features': None,...           0.643048   \n",
       "11  {'criterion': 'entropy', 'max_features': None,...           0.643048   \n",
       "12  {'criterion': 'log_loss', 'max_features': 'sqr...           0.643048   \n",
       "13  {'criterion': 'log_loss', 'max_features': 'sqr...           0.643048   \n",
       "14  {'criterion': 'log_loss', 'max_features': 'log...           0.643048   \n",
       "15  {'criterion': 'log_loss', 'max_features': 'log...           0.643048   \n",
       "16  {'criterion': 'log_loss', 'max_features': None...           0.643048   \n",
       "17  {'criterion': 'log_loss', 'max_features': None...           0.643048   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.696524            0.68984           0.686747   \n",
       "1            0.696524            0.68984           0.686747   \n",
       "2            0.696524            0.68984           0.686747   \n",
       "3            0.696524            0.68984           0.686747   \n",
       "4            0.696524            0.68984           0.685408   \n",
       "5            0.696524            0.68984           0.685408   \n",
       "6            0.696524            0.68984           0.686747   \n",
       "7            0.696524            0.68984           0.686747   \n",
       "8            0.696524            0.68984           0.686747   \n",
       "9            0.696524            0.68984           0.686747   \n",
       "10           0.696524            0.68984           0.685408   \n",
       "11           0.696524            0.68984           0.686747   \n",
       "12           0.696524            0.68984           0.686747   \n",
       "13           0.696524            0.68984           0.686747   \n",
       "14           0.696524            0.68984           0.686747   \n",
       "15           0.696524            0.68984           0.686747   \n",
       "16           0.696524            0.68984           0.685408   \n",
       "17           0.696524            0.68984           0.686747   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.702811         0.683794        0.021115                1  \n",
       "1            0.702811         0.683794        0.021115                1  \n",
       "2            0.702811         0.683794        0.021115                1  \n",
       "3            0.702811         0.683794        0.021115                1  \n",
       "4            0.702811         0.683526        0.021084               15  \n",
       "5            0.702811         0.683526        0.021084               15  \n",
       "6            0.702811         0.683794        0.021115                1  \n",
       "7            0.702811         0.683794        0.021115                1  \n",
       "8            0.702811         0.683794        0.021115                1  \n",
       "9            0.702811         0.683794        0.021115                1  \n",
       "10           0.702811         0.683526        0.021084               15  \n",
       "11           0.702811         0.683794        0.021115                1  \n",
       "12           0.702811         0.683794        0.021115                1  \n",
       "13           0.702811         0.683794        0.021115                1  \n",
       "14           0.702811         0.683794        0.021115                1  \n",
       "15           0.702811         0.683794        0.021115                1  \n",
       "16           0.702811         0.683526        0.021084               15  \n",
       "17           0.702811         0.683794        0.021115                1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1b103e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1. Age_23-26', '2. Gender_Male', '3. University_Dhaka University (DU)',\n",
       "       '3. University_Dhaka University of Engineering and Technology (DUET)',\n",
       "       '3. University_Independent University, Bangladesh (IUB)',\n",
       "       '3. University_Islamic University of Technology (IUT)',\n",
       "       '3. University_North South University (NSU)',\n",
       "       '4. Department_Business and Entrepreneurship Studies',\n",
       "       '4. Department_Engineering - CS / CSE / CSC / Similar to CS',\n",
       "       '4. Department_Other', '5. Academic Year_Fourth Year or Equivalent',\n",
       "       '5. Academic Year_Other', '5. Academic Year_Second Year or Equivalent',\n",
       "       '5. Academic Year_Third Year or Equivalent',\n",
       "       '7. Did you receive a waiver or scholarship at your university?_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selected_features[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfecab01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Age: 27\n",
      "Gender (male/female/m/f): m\n",
      "Enter: 1 for Independent University, Bangladesh (IUB)\n",
      "Enter: 2 for American International University Bangladesh (AIUB)\n",
      "Enter: 3 for North South University (NSU)\n",
      "Enter: 4 for Islamic University of Technology (IUT)\n",
      "Enter: 5 for Patuakhali Science and Technology University\n",
      "Enter: 6 for Rajshahi University of Engineering and Technology (RUET)\n",
      "Enter: 7 for Dhaka University (DU)\n",
      "Enter: 8 for Bangladesh University of Engineering and Technology (BUET)\n",
      "Enter: 9 for Dhaka University of Engineering and Technology (DUET)\n",
      "Enter: 10 for United International University (UIU)\n",
      "Enter: 11 for East West University (EWU)\n",
      "Enter: 12 for BRAC University\n",
      "Enter: 13 for Bangladesh Agricultural University (BAU)\n",
      "Enter: 14 for Rajshahi University (RU)\n",
      "Enter: 15 for Daffodil University\n",
      "Enter Here:7\n",
      "Enter: 1 for Engineering - CS / CSE / CSC / Similar to CS\n",
      "Enter: 2 for Engineering - EEE/ ECE / Similar to EEE\n",
      "Enter: 3 for Other\n",
      "Enter: 4 for Business and Entrepreneurship Studies\n",
      "Enter: 5 for Environmental and Life Sciences\n",
      "Enter: 6 for Engineering - Mechanical Engineering / Similar to ME\n",
      "Enter: 7 for Engineering - Civil Engineering / Similar to CE\n",
      "Enter: 8 for Biological Sciences\n",
      "Enter: 9 for Engineering - Other\n",
      "Enter: 10 for Liberal Arts and Social Sciences\n",
      "Enter: 11 for Law and Human Rights\n",
      "Enter: 12 for Pharmacy and Public Health\n",
      "Enter Here:1\n",
      "Enter: 1 for Second Year or Equivalent\n",
      "Enter: 2 for Third Year or Equivalent\n",
      "Enter: 3 for Other\n",
      "Enter: 4 for First Year or Equivalent\n",
      "Enter: 5 for Fourth Year or Equivalent\n",
      "Enter Here:4\n",
      "Enter: 1 for 2.50 - 2.99\n",
      "Enter: 2 for 3.00 - 3.39\n",
      "Enter: 3 for 3.40 - 3.79\n",
      "Enter: 4 for 3.80 - 4.00\n",
      "Enter: 5 for Below 2.50\n",
      "Enter: 6 for Other\n",
      "Enter Here:4\n",
      "Enter: 1 for No\n",
      "Enter: 2 for Yes\n",
      "Enter Here:2\n",
      "You're Age:27, You are grouped under the age group: 27-30\n",
      "You're Gender:Male\n",
      "You're Selected University:Dhaka University (DU)\n",
      "You're Selected Department:Engineering - CS / CSE / CSC / Similar to CS\n",
      "You're Selected Academic Year:First Year or Equivalent\n",
      "You're CGPA:3, You are grouped under the CGPA group: 3.80 - 4.00\n",
      "You're Scholarship Status:Yes\n"
     ]
    }
   ],
   "source": [
    "# university = int(input(\"Enter:\\n1 for IUB\\n2 for AIUB\\n3 for NSU\\n4 for IUT\\n5 for PSTU\\n6 for RUET\\n7 for DU\\n8 for BUET\\n9 for DUET\\n10 for UIU\\n11 for EWU\\n12 for BRAC\\n13 for BAU\\n14 for RU\\n15 for Daffodil\\n\"))-1\n",
    "entered_age = int(input(\"Enter your Age: \"))\n",
    "age=\"\"\n",
    "if(entered_age<18):\n",
    "    age=\"Below 18\"\n",
    "elif entered_age<=22:\n",
    "    age=\"18-22\"\n",
    "elif entered_age<=26:\n",
    "    age=\"23-26\"\n",
    "elif entered_age<=30:\n",
    "    age=\"27-30\"\n",
    "else:\n",
    "    age=\"Above 30\"\n",
    "    \n",
    "entered_gender = input(\"Gender (male/female/m/f): \").lower()[0:1]\n",
    "\n",
    "if \"m\" in entered_gender:\n",
    "    gender=\"Male\"\n",
    "elif \"f\" in entered_gender:\n",
    "    gender=\"Female\"\n",
    "else:\n",
    "    gender=\"Prefer not to say\"\n",
    "    \n",
    "for i,value in enumerate(x[\"3. University\"].unique()):\n",
    "    \n",
    "    print(f\"Enter: {i+1} for {value}\")\n",
    "    \n",
    "university = int(input(\"Enter Here:\"))-1\n",
    "    \n",
    "selected_university = \"\"\n",
    "for i,value in enumerate(x[\"3. University\"].unique()):\n",
    "    if(university==i):\n",
    "        selected_university=value\n",
    "        break;\n",
    "\n",
    "        \n",
    "for i,value in enumerate(x[\"4. Department\"].unique()):\n",
    "    \n",
    "    print(f\"Enter: {i+1} for {value}\")\n",
    "    \n",
    "department = int(input(\"Enter Here:\"))-1\n",
    "    \n",
    "selected_department = \"\"\n",
    "for i,value in enumerate(x[\"4. Department\"].unique()):\n",
    "    if(department==i):\n",
    "        selected_department=value\n",
    "        break;\n",
    "    \n",
    "for i,value in enumerate(x[\"5. Academic Year\"].unique()):\n",
    "    \n",
    "    print(f\"Enter: {i+1} for {value}\")\n",
    "    \n",
    "academic_year = int(input(\"Enter Here:\"))-1\n",
    "    \n",
    "selected_academic_year = \"\"\n",
    "for i,value in enumerate(x[\"5. Academic Year\"].unique()):\n",
    "    if(academic_year==i):\n",
    "        selected_academic_year=value\n",
    "        break;\n",
    "        \n",
    "for i,value in enumerate(x[\"6. Current CGPA\"].unique()):\n",
    "    \n",
    "    print(f\"Enter: {i+1} for {value}\")\n",
    "    \n",
    "current_cgpa = int(input(\"Enter Here:\"))-1\n",
    "    \n",
    "selected_current_cgpa = \"\"\n",
    "for i,value in enumerate(x[\"6. Current CGPA\"].unique()):\n",
    "    if(current_cgpa==i):\n",
    "        selected_current_cgpa=value\n",
    "        break;\n",
    "        \n",
    "for i,value in enumerate(x[\"7. Did you receive a waiver or scholarship at your university?\"].unique()):\n",
    "    \n",
    "    print(f\"Enter: {i+1} for {value}\")\n",
    "    \n",
    "entered_scholarship = int(input(\"Enter Here:\"))-1\n",
    "    \n",
    "selected_scholarship = \"\"\n",
    "for i,value in enumerate(x[\"7. Did you receive a waiver or scholarship at your university?\"].unique()):\n",
    "    if(entered_scholarship==i):\n",
    "        selected_scholarship=value\n",
    "        break;\n",
    "\n",
    "    \n",
    "print(f\"You're Age:{entered_age}, You are grouped under the age group: {age}\")\n",
    "print(f\"You're Gender:{gender}\")  \n",
    "\n",
    "print(f\"You're Selected University:{selected_university}\")\n",
    "print(f\"You're Selected Department:{selected_department}\")  \n",
    "print(f\"You're Selected Academic Year:{selected_academic_year}\")\n",
    "print(f\"You're CGPA:{current_cgpa}, You are grouped under the CGPA group: {selected_current_cgpa}\")\n",
    "print(f\"You're Scholarship Status:{selected_scholarship}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25e09719",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = [age,gender,selected_university,selected_department,selected_academic_year,selected_current_cgpa,selected_scholarship]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2d3964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfeatures = [0 for i in Selected_features[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a841254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in user_inputs:\n",
    "    for index,j in enumerate(Selected_features[3]):\n",
    "        if j.endswith(i):\n",
    "            if j.split(\"_\")[-1] == i:\n",
    "                inputfeatures[index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f440fdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict([inputfeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ef9564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdata = pd.read_csv(\"PreAnxiety.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e7d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in newdata.iloc[:,0:7].values:\n",
    "#     inputfeatures = [0] * len(Selected_features[3])\n",
    "#     for i in k:\n",
    "#         for index,j in enumerate(Selected_features[3]):\n",
    "#             if j.endswith(i):\n",
    "#                 if j.split(\"_\")[-1] == i:\n",
    "#                     inputfeatures[index] = 1\n",
    "#     print(best_model.predict([inputfeatures]))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdata.iloc[:,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a23cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34604d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../4.Final Model/AnxietyModel.sav',\"wb\") as file:\n",
    "    pickle.dump(best_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d84ea033",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../4.Final Model/SelectedFeatures.txt',\"w\") as file:\n",
    "    for feature in Selected_features[3]:\n",
    "        file.write(f\"{feature}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77bbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
